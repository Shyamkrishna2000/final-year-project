{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:38:11.158116Z",
     "iopub.status.busy": "2022-04-12T15:38:11.157654Z",
     "iopub.status.idle": "2022-04-12T15:38:11.490102Z",
     "shell.execute_reply": "2022-04-12T15:38:11.489258Z",
     "shell.execute_reply.started": "2022-04-12T15:38:11.157997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the file tokens_clean.txt and store the cleaned captions in a dictionary\n",
    "import json\n",
    "\n",
    "content = None\n",
    "\n",
    "with open (\"../input/dataset/tokens_clean.txt\", 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "json_acceptable_string = content.replace(\"'\", \"\\\"\")\n",
    "content = json.loads(json_acceptable_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:38:32.575994Z",
     "iopub.status.busy": "2022-04-12T15:38:32.575689Z",
     "iopub.status.idle": "2022-04-12T15:38:32.580722Z",
     "shell.execute_reply": "2022-04-12T15:38:32.580010Z",
     "shell.execute_reply.started": "2022-04-12T15:38:32.575954Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:38:35.409447Z",
     "iopub.status.busy": "2022-04-12T15:38:35.408826Z",
     "iopub.status.idle": "2022-04-12T15:38:35.788495Z",
     "shell.execute_reply": "2022-04-12T15:38:35.787645Z",
     "shell.execute_reply.started": "2022-04-12T15:38:35.409406Z"
    }
   },
   "outputs": [],
   "source": [
    "#Iterate over the captions word by word, and append each word to total_words\n",
    "total_words = []\n",
    "\n",
    "for key in content.keys():\n",
    "    for caption in content[key]:\n",
    "        for i in caption.split():\n",
    "            total_words.append(i)\n",
    "\n",
    "print(\"Total Words = %d\" %len(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:39:14.167880Z",
     "iopub.status.busy": "2022-04-12T15:39:14.167587Z",
     "iopub.status.idle": "2022-04-12T15:39:14.395649Z",
     "shell.execute_reply": "2022-04-12T15:39:14.394901Z",
     "shell.execute_reply.started": "2022-04-12T15:39:14.167847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the frequency of occurrence of each word, and store it in a dictionary of word-freq\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter(total_words)\n",
    "freq_cnt = dict(counter)\n",
    "\n",
    "print(\"Number of unique words = \" + str(len(freq_cnt.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:39:45.314738Z",
     "iopub.status.busy": "2022-04-12T15:39:45.314445Z",
     "iopub.status.idle": "2022-04-12T15:39:45.379911Z",
     "shell.execute_reply": "2022-04-12T15:39:45.379117Z",
     "shell.execute_reply.started": "2022-04-12T15:39:45.314709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the word-freq pairs (from the dictionary freq_cnt) in a list, sorted in decreasing order of frequency\n",
    "sorted_freq_cnt = sorted(freq_cnt.items(), reverse=True, key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:39:47.184299Z",
     "iopub.status.busy": "2022-04-12T15:39:47.184023Z",
     "iopub.status.idle": "2022-04-12T15:39:47.224763Z",
     "shell.execute_reply": "2022-04-12T15:39:47.224018Z",
     "shell.execute_reply.started": "2022-04-12T15:39:47.184264Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "\n",
    "#Filter off those words whose frequency of occurrence in less than threshold\n",
    "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1]>threshold]\n",
    "# Store these common words in total_words\n",
    "total_words = [x[0] for x in sorted_freq_cnt]\n",
    "\n",
    "print(\"Number of common unique words = \" + str(len(total_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARE TRAIN AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:39:50.686522Z",
     "iopub.status.busy": "2022-04-12T15:39:50.685780Z",
     "iopub.status.idle": "2022-04-12T15:39:50.714253Z",
     "shell.execute_reply": "2022-04-12T15:39:50.713434Z",
     "shell.execute_reply.started": "2022-04-12T15:39:50.686486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read training and testing image names\n",
    "\n",
    "train_file_data = \"\"\n",
    "test_file_data = \"\"\n",
    "\n",
    "with open (\"../input/dataset/flickr30k_train.txt\", 'r') as file:\n",
    "    train_file_data = file.read()\n",
    "\n",
    "with open (\"../input/dataset/flickr30k_test.txt\", 'r') as file:\n",
    "    test_file_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:39:53.752047Z",
     "iopub.status.busy": "2022-04-12T15:39:53.751767Z",
     "iopub.status.idle": "2022-04-12T15:39:53.766904Z",
     "shell.execute_reply": "2022-04-12T15:39:53.765982Z",
     "shell.execute_reply.started": "2022-04-12T15:39:53.752015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtain a list of train and test images\n",
    "train_data = [img_file_name for img_file_name in train_file_data.split(\"\\n\")[:-1]]\n",
    "test_data = [img_file_name for img_file_name in test_file_data.split(\"\\n\")[:-1]]\n",
    "\n",
    "# Obtain image ID from image file name\n",
    "train_data = [image.split(\".\")[0] for image in train_data]\n",
    "test_data = [image.split(\".\")[0] for image in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:39:55.273727Z",
     "iopub.status.busy": "2022-04-12T15:39:55.273104Z",
     "iopub.status.idle": "2022-04-12T15:39:55.280705Z",
     "shell.execute_reply": "2022-04-12T15:39:55.279997Z",
     "shell.execute_reply.started": "2022-04-12T15:39:55.273685Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:40:37.844100Z",
     "iopub.status.busy": "2022-04-12T15:40:37.843318Z",
     "iopub.status.idle": "2022-04-12T15:40:37.943259Z",
     "shell.execute_reply": "2022-04-12T15:40:37.942422Z",
     "shell.execute_reply.started": "2022-04-12T15:40:37.844056Z"
    }
   },
   "outputs": [],
   "source": [
    "# For each imageID in train_data, store its captions in a dictionary \n",
    "\n",
    "train_content = {}\n",
    "\n",
    "for imageID in train_data:\n",
    "    train_content[imageID] = []\n",
    "    for caption in content[imageID]:\n",
    "        # Add a start sequence token in the beginning and an end sequence token at the end\n",
    "        cap_to_append = \"startseq \" + caption + \" endseq\"\n",
    "        train_content[imageID].append(cap_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:40:39.738272Z",
     "iopub.status.busy": "2022-04-12T15:40:39.737327Z",
     "iopub.status.idle": "2022-04-12T15:40:39.743894Z",
     "shell.execute_reply": "2022-04-12T15:40:39.743149Z",
     "shell.execute_reply.started": "2022-04-12T15:40:39.738228Z"
    }
   },
   "outputs": [],
   "source": [
    "train_content['1001896054']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACT FEATURES FROM IMAGES USING VGG16 ARCHIECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:40:43.627693Z",
     "iopub.status.busy": "2022-04-12T15:40:43.626783Z",
     "iopub.status.idle": "2022-04-12T15:40:53.468111Z",
     "shell.execute_reply": "2022-04-12T15:40:53.467147Z",
     "shell.execute_reply.started": "2022-04-12T15:40:43.627637Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "\n",
    "model = VGG16(weights = 'imagenet', input_shape = (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:42:17.499152Z",
     "iopub.status.busy": "2022-04-12T15:42:17.498678Z",
     "iopub.status.idle": "2022-04-12T15:42:17.518419Z",
     "shell.execute_reply": "2022-04-12T15:42:17.517609Z",
     "shell.execute_reply.started": "2022-04-12T15:42:17.499110Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:42:54.875038Z",
     "iopub.status.busy": "2022-04-12T15:42:54.874643Z",
     "iopub.status.idle": "2022-04-12T15:42:54.885686Z",
     "shell.execute_reply": "2022-04-12T15:42:54.884896Z",
     "shell.execute_reply.started": "2022-04-12T15:42:54.874991Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model_new = Model (model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:42:56.939983Z",
     "iopub.status.busy": "2022-04-12T15:42:56.939676Z",
     "iopub.status.idle": "2022-04-12T15:42:56.955241Z",
     "shell.execute_reply": "2022-04-12T15:42:56.954450Z",
     "shell.execute_reply.started": "2022-04-12T15:42:56.939930Z"
    }
   },
   "outputs": [],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:43:07.407744Z",
     "iopub.status.busy": "2022-04-12T15:43:07.407138Z",
     "iopub.status.idle": "2022-04-12T15:43:07.413405Z",
     "shell.execute_reply": "2022-04-12T15:43:07.412390Z",
     "shell.execute_reply.started": "2022-04-12T15:43:07.407701Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image (img):\n",
    "    img = image.load_img(img, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    # Convert 3D tensor to a 4D tendor\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    #Normalize image accoring to VGG16 requirement\n",
    "    img = preprocess_input(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:43:09.917738Z",
     "iopub.status.busy": "2022-04-12T15:43:09.917456Z",
     "iopub.status.idle": "2022-04-12T15:43:10.269746Z",
     "shell.execute_reply": "2022-04-12T15:43:10.266826Z",
     "shell.execute_reply.started": "2022-04-12T15:43:09.917706Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = preprocess_image(\"../input/flickr30k/Images/101362650.jpg\")\n",
    "print(img.shape)\n",
    "plt.imshow(img[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:43:13.904820Z",
     "iopub.status.busy": "2022-04-12T15:43:13.904544Z",
     "iopub.status.idle": "2022-04-12T15:43:13.909645Z",
     "shell.execute_reply": "2022-04-12T15:43:13.908915Z",
     "shell.execute_reply.started": "2022-04-12T15:43:13.904788Z"
    }
   },
   "outputs": [],
   "source": [
    "# A wrapper function, which inputs an image and returns its encoding (feature vector)\n",
    "def encode_image (img):\n",
    "    img = preprocess_image(img)\n",
    "    feature_vector = model_new.predict(img)\n",
    "\n",
    "    feature_vector = feature_vector.reshape((-1,))\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:43:18.815599Z",
     "iopub.status.busy": "2022-04-12T15:43:18.815325Z",
     "iopub.status.idle": "2022-04-12T15:43:18.819803Z",
     "shell.execute_reply": "2022-04-12T15:43:18.819009Z",
     "shell.execute_reply.started": "2022-04-12T15:43:18.815569Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_PATH = \"../input/flickr30k/Images/flickr30k_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T08:11:17.357241Z",
     "iopub.status.busy": "2022-03-29T08:11:17.356706Z",
     "iopub.status.idle": "2022-03-29T08:11:23.622295Z",
     "shell.execute_reply": "2022-03-29T08:11:23.621291Z",
     "shell.execute_reply.started": "2022-03-29T08:11:17.35719Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "train_encoding = {}\n",
    "# Create a dictionary of iamgeID and its feature vector\n",
    "\n",
    "start_time = time()\n",
    "for index, imageID in enumerate (train_data):\n",
    "    image_path = IMG_PATH+\"/\" + imageID + \".jpg\"\n",
    "    \n",
    "    train_encoding[imageID] = encode_image(image_path)\n",
    "\n",
    "    # Print progress\n",
    "    if index%100 == 0:\n",
    "        print(\"Encoding in progress... STEP\", index)\n",
    "\n",
    "end_time = time()\n",
    "print(\"Total time taken:\", end_time-start_time, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the above computed features on the disk\n",
    "# Use pickle to dump the entire data\n",
    "import pickle\n",
    "\n",
    "with open(\"encoded_train_features.pkl\", \"wb\") as file:\n",
    "    # Pickle allows to store any object as a file on the disk\n",
    "    pickle.dump(train_encoding, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoding = {}\n",
    "# Create a dictionary of iamgeID and its feature vector\n",
    "\n",
    "start_time = time()\n",
    "for index, imageID in enumerate (test_data):\n",
    "    image_path = \"data/Images/\" + imageID + \".jpg\"\n",
    "    \n",
    "    test_encoding[imageID] = encode_image(image_path)\n",
    "\n",
    "    # Print progress\n",
    "    if index%100 == 0:\n",
    "        print(\"Encoding in progress... STEP\", index)\n",
    "\n",
    "end_time = time()\n",
    "print(\"Total time taken:\", end_time-start_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"encoded_test_features.pkl\", \"wb\") as file:\n",
    "    pickle.dump(test_encoding, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS THE CAPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:43:29.895441Z",
     "iopub.status.busy": "2022-04-12T15:43:29.894911Z",
     "iopub.status.idle": "2022-04-12T15:43:29.914765Z",
     "shell.execute_reply": "2022-04-12T15:43:29.913994Z",
     "shell.execute_reply.started": "2022-04-12T15:43:29.895400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the word-to-index and index-to-word mappings\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "\n",
    "for i, word in enumerate(total_words):\n",
    "    word_to_index[word] = i+1\n",
    "    index_to_word[i+1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:43:32.022096Z",
     "iopub.status.busy": "2022-04-12T15:43:32.021805Z",
     "iopub.status.idle": "2022-04-12T15:43:32.027918Z",
     "shell.execute_reply": "2022-04-12T15:43:32.027120Z",
     "shell.execute_reply.started": "2022-04-12T15:43:32.022064Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:43:34.584555Z",
     "iopub.status.busy": "2022-04-12T15:43:34.583923Z",
     "iopub.status.idle": "2022-04-12T15:43:34.589545Z",
     "shell.execute_reply": "2022-04-12T15:43:34.588803Z",
     "shell.execute_reply.started": "2022-04-12T15:43:34.584512Z"
    }
   },
   "outputs": [],
   "source": [
    "print(index_to_word[5])\n",
    "print(word_to_index['and'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:43:36.811501Z",
     "iopub.status.busy": "2022-04-12T15:43:36.811146Z",
     "iopub.status.idle": "2022-04-12T15:43:36.816565Z",
     "shell.execute_reply": "2022-04-12T15:43:36.815821Z",
     "shell.execute_reply.started": "2022-04-12T15:43:36.811455Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add startseq and endseq also to the mappings\n",
    "index_to_word[5137] = 'startseq'\n",
    "word_to_index['startseq'] = 5137\n",
    "\n",
    "index_to_word[5138] = 'endseq'\n",
    "word_to_index['endseq'] = 5138\n",
    "\n",
    "VOCAB_SIZE = len(word_to_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:43:40.227736Z",
     "iopub.status.busy": "2022-04-12T15:43:40.226986Z",
     "iopub.status.idle": "2022-04-12T15:43:40.232783Z",
     "shell.execute_reply": "2022-04-12T15:43:40.231685Z",
     "shell.execute_reply.started": "2022-04-12T15:43:40.227695Z"
    }
   },
   "outputs": [],
   "source": [
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T13:52:22.656849Z",
     "iopub.status.busy": "2022-04-12T13:52:22.656199Z",
     "iopub.status.idle": "2022-04-12T13:52:22.897246Z",
     "shell.execute_reply": "2022-04-12T13:52:22.895886Z",
     "shell.execute_reply.started": "2022-04-12T13:52:22.656812Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../input/dataset/word_to_idx.pkl\", \"wb\") as file:\n",
    "    pickle.dump(word_to_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/textFiles/idx_to_word.pkl\", \"wb\") as file:\n",
    "    pickle.dump(index_to_word, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:06.341562Z",
     "iopub.status.busy": "2022-04-12T15:44:06.341282Z",
     "iopub.status.idle": "2022-04-12T15:44:06.529346Z",
     "shell.execute_reply": "2022-04-12T15:44:06.528492Z",
     "shell.execute_reply.started": "2022-04-12T15:44:06.341532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the maximum length of a caption\n",
    "max_len = 0\n",
    "\n",
    "for cap_list in train_content.keys():\n",
    "    for caption in train_content[cap_list]:\n",
    "        max_len = max(max_len, len(caption.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:08.389604Z",
     "iopub.status.busy": "2022-04-12T15:44:08.389039Z",
     "iopub.status.idle": "2022-04-12T15:44:08.394361Z",
     "shell.execute_reply": "2022-04-12T15:44:08.393484Z",
     "shell.execute_reply.started": "2022-04-12T15:44:08.389565Z"
    }
   },
   "outputs": [],
   "source": [
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:13.418570Z",
     "iopub.status.busy": "2022-04-12T15:44:13.418008Z",
     "iopub.status.idle": "2022-04-12T15:44:13.425082Z",
     "shell.execute_reply": "2022-04-12T15:44:13.424329Z",
     "shell.execute_reply.started": "2022-04-12T15:44:13.418531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the Glove word Embeddings\n",
    "# This contains 50-dimensional embeddings for 6 Billion English words\n",
    "file = open(\"../input/glovefile/glove.6B.50d.txt\",encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:16.203096Z",
     "iopub.status.busy": "2022-04-12T15:44:16.202689Z",
     "iopub.status.idle": "2022-04-12T15:44:22.281180Z",
     "shell.execute_reply": "2022-04-12T15:44:22.280362Z",
     "shell.execute_reply.started": "2022-04-12T15:44:16.203052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a mapping from word to embedding\n",
    "embeddings_index = {} # empty dictionary\n",
    "\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "\n",
    "    word = values[0]\n",
    "    coefs = np.array (values[1:], dtype='float')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:37.185887Z",
     "iopub.status.busy": "2022-04-12T15:44:37.185573Z",
     "iopub.status.idle": "2022-04-12T15:44:37.194146Z",
     "shell.execute_reply": "2022-04-12T15:44:37.193168Z",
     "shell.execute_reply.started": "2022-04-12T15:44:37.185854Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_index[\"apple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:39.129362Z",
     "iopub.status.busy": "2022-04-12T15:44:39.128795Z",
     "iopub.status.idle": "2022-04-12T15:44:39.168697Z",
     "shell.execute_reply": "2022-04-12T15:44:39.167872Z",
     "shell.execute_reply.started": "2022-04-12T15:44:39.129322Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, embedding_dim))\n",
    "\n",
    "for word, i in word_to_index.items():\n",
    "    #if i < max_words:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in the embedding index will be all zeros\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:43.749958Z",
     "iopub.status.busy": "2022-04-12T15:44:43.749143Z",
     "iopub.status.idle": "2022-04-12T15:44:43.755280Z",
     "shell.execute_reply": "2022-04-12T15:44:43.754331Z",
     "shell.execute_reply.started": "2022-04-12T15:44:43.749905Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:47.897266Z",
     "iopub.status.busy": "2022-04-12T15:44:47.896855Z",
     "iopub.status.idle": "2022-04-12T15:44:47.924457Z",
     "shell.execute_reply": "2022-04-12T15:44:47.923763Z",
     "shell.execute_reply.started": "2022-04-12T15:44:47.897222Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "\n",
    "#Convert feature vector of image to smaller vector\n",
    "\n",
    "#Output of VGG goes into following input layer \n",
    "inp_img_features = Input(shape=(4096,))\n",
    "\n",
    "inp_img1 = Dropout(0.4)(inp_img_features)\n",
    "inp_img2 = Dense(256, activation='relu')(inp_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:50.002508Z",
     "iopub.status.busy": "2022-04-12T15:44:50.002179Z",
     "iopub.status.idle": "2022-04-12T15:44:50.805457Z",
     "shell.execute_reply": "2022-04-12T15:44:50.804669Z",
     "shell.execute_reply.started": "2022-04-12T15:44:50.002471Z"
    }
   },
   "outputs": [],
   "source": [
    "#Now take Captions as input\n",
    "\n",
    "#Actual input size will be (batch_size x max_length_of_caption)\n",
    "#But here we specify only for one example\n",
    "inp_cap = Input(shape=(max_len,))\n",
    "inp_cap1 = Embedding(input_dim=VOCAB_SIZE, output_dim=50, mask_zero=True)(inp_cap)\n",
    "inp_cap2 = Dropout(0.4)(inp_cap1)\n",
    "inp_cap3 = LSTM(256)(inp_cap2)\n",
    "# inp_cap3 captures the entire sentence that has been generated till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:53.436429Z",
     "iopub.status.busy": "2022-04-12T15:44:53.435821Z",
     "iopub.status.idle": "2022-04-12T15:44:53.463577Z",
     "shell.execute_reply": "2022-04-12T15:44:53.462902Z",
     "shell.execute_reply.started": "2022-04-12T15:44:53.436389Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers.merge import add\n",
    "\n",
    "# Decode the inputs\n",
    "\n",
    "# So, an image (224x224x3) goes through Vgg16\n",
    "# Then as 4096 dimensional it goes through the above earlier architecture\n",
    "# The final output is inp_img2 (256 dimensional) which now goes through the Decoder \n",
    "\n",
    "# Similarly for the captions which initially have shape (batch_size x max_len)\n",
    "# Then after passing through Embedding layer comes out as (batch_size x max_len x 50(embedding_size)))\n",
    "# Then it passes through the above LSTM layer and comes out as inp_cap3 (a 256 dimensional vector)\n",
    "\n",
    "# Add the two above tensors\n",
    "decoder1 = add([inp_img2, inp_cap3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(VOCAB_SIZE, activation='softmax')(decoder2)\n",
    "\n",
    "# Combined model\n",
    "model = Model (inputs=[inp_img_features, inp_cap], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:44:56.644914Z",
     "iopub.status.busy": "2022-04-12T15:44:56.644639Z",
     "iopub.status.idle": "2022-04-12T15:44:56.658721Z",
     "shell.execute_reply": "2022-04-12T15:44:56.657671Z",
     "shell.execute_reply.started": "2022-04-12T15:44:56.644883Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:45:09.108669Z",
     "iopub.status.busy": "2022-04-12T15:45:09.107846Z",
     "iopub.status.idle": "2022-04-12T15:45:09.467621Z",
     "shell.execute_reply": "2022-04-12T15:45:09.466764Z",
     "shell.execute_reply.started": "2022-04-12T15:45:09.108619Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:45:13.664754Z",
     "iopub.status.busy": "2022-04-12T15:45:13.664173Z",
     "iopub.status.idle": "2022-04-12T15:45:13.677193Z",
     "shell.execute_reply": "2022-04-12T15:45:13.676304Z",
     "shell.execute_reply.started": "2022-04-12T15:45:13.664711Z"
    }
   },
   "outputs": [],
   "source": [
    "model.layers[2].set_weights([embedding_matrix])\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:45:15.388037Z",
     "iopub.status.busy": "2022-04-12T15:45:15.387370Z",
     "iopub.status.idle": "2022-04-12T15:45:15.406713Z",
     "shell.execute_reply": "2022-04-12T15:45:15.405861Z",
     "shell.execute_reply.started": "2022-04-12T15:45:15.387995Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE A DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:45:18.679993Z",
     "iopub.status.busy": "2022-04-12T15:45:18.679366Z",
     "iopub.status.idle": "2022-04-12T15:45:18.844124Z",
     "shell.execute_reply": "2022-04-12T15:45:18.843324Z",
     "shell.execute_reply.started": "2022-04-12T15:45:18.679927Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def data_generator (train_content, train_encoding, word_to_index, max_len, batch_size):\n",
    "    X1, X2, y = [], [], []\n",
    "    n = 0\n",
    "\n",
    "    while True:\n",
    "        for imageID, cap_list in train_content.items():\n",
    "            n += 1\n",
    "\n",
    "            image = train_encoding [imageID]\n",
    "\n",
    "            for caption in cap_list:\n",
    "                idx_seq = [word_to_index[word] for word in caption.split() if word in word_to_index]\n",
    "\n",
    "                for i in range (1, len(idx_seq)):\n",
    "                    xi = idx_seq[0 : i] # The input sequence of words\n",
    "                    yi = idx_seq[i] # The next word after the above sequence (this is expected to be predicted)\n",
    "\n",
    "                    # Add a padding of zeros ao lengths of input sequences become equal\n",
    "                    xi = pad_sequences([xi], maxlen=max_len, value=0, padding='post')[0] # Take the first row only, since this method inputs & returns a 2D array\n",
    "                    # Convert the expected word to One Hot vector notation\n",
    "                    yi = to_categorical([yi], num_classes=VOCAB_SIZE)[0]\n",
    "\n",
    "                    X1.append(image)\n",
    "                    X2.append(xi)\n",
    "                    y.append(yi)\n",
    "                    if n == batch_size:\n",
    "                        X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "                        yield [X1, X2], y\n",
    "                        X1, X2, y = list(), list(), list()\n",
    "                        n = 0\n",
    "                        \n",
    "                \n",
    "                    \n",
    "                    \n",
    "#                     print('DEBUGGING...............................................')\n",
    "#                     print(image.shape)\n",
    "#                     print(\"xi \",xi)\n",
    "#                     print(\"yi \",yi)\n",
    "#                     break\n",
    "\n",
    "#                 if n==batch_size:\n",
    "#                     yield [[np.array(X1), np.array(X2)], np.array(y) ]\n",
    "                    \n",
    "                    \n",
    "#                     X1, X2, y = [], [], []\n",
    "#                     n=0\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:45:22.571113Z",
     "iopub.status.busy": "2022-04-12T15:45:22.570550Z",
     "iopub.status.idle": "2022-04-12T15:45:25.900966Z",
     "shell.execute_reply": "2022-04-12T15:45:25.900114Z",
     "shell.execute_reply.started": "2022-04-12T15:45:22.571072Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../input/encoding/encoded_train_features.pkl', 'rb') as f:\n",
    "    train_encoding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:51:11.281424Z",
     "iopub.status.busy": "2022-04-12T15:51:11.280476Z",
     "iopub.status.idle": "2022-04-12T15:51:11.285082Z",
     "shell.execute_reply": "2022-04-12T15:51:11.284324Z",
     "shell.execute_reply.started": "2022-04-12T15:51:11.281383Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "batch_size = 32\n",
    "steps = len(train_content)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:51:12.452416Z",
     "iopub.status.busy": "2022-04-12T15:51:12.451462Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    # Create an instance of the generator\n",
    "    generator = data_generator(train_content, train_encoding, word_to_index, max_len, batch_size)\n",
    "    #for i in generator:\n",
    "        #print(i,len(i))\n",
    "    \n",
    "    model.fit(generator, steps_per_epoch=steps)\n",
    "    model.save('model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:14:05.738512Z",
     "iopub.status.busy": "2022-03-28T12:14:05.738235Z",
     "iopub.status.idle": "2022-03-28T12:14:05.750808Z",
     "shell.execute_reply": "2022-03-28T12:14:05.749282Z",
     "shell.execute_reply.started": "2022-03-28T12:14:05.738483Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:46:01.588575Z",
     "iopub.status.busy": "2022-04-12T15:46:01.587816Z",
     "iopub.status.idle": "2022-04-12T15:46:01.644325Z",
     "shell.execute_reply": "2022-04-12T15:46:01.643500Z",
     "shell.execute_reply.started": "2022-04-12T15:46:01.588534Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('./model_13.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:46:04.799166Z",
     "iopub.status.busy": "2022-04-12T15:46:04.798811Z",
     "iopub.status.idle": "2022-04-12T15:46:04.806693Z",
     "shell.execute_reply": "2022-04-12T15:46:04.805824Z",
     "shell.execute_reply.started": "2022-04-12T15:46:04.799126Z"
    }
   },
   "outputs": [],
   "source": [
    "images = '../input/flickr30k/Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T09:25:29.231828Z",
     "iopub.status.busy": "2022-03-29T09:25:29.231551Z",
     "iopub.status.idle": "2022-03-29T09:25:29.240165Z",
     "shell.execute_reply": "2022-03-29T09:25:29.239395Z",
     "shell.execute_reply.started": "2022-03-29T09:25:29.231797Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:46:09.787613Z",
     "iopub.status.busy": "2022-04-12T15:46:09.786848Z",
     "iopub.status.idle": "2022-04-12T15:46:09.794871Z",
     "shell.execute_reply": "2022-04-12T15:46:09.794101Z",
     "shell.execute_reply.started": "2022-04-12T15:46:09.787572Z"
    }
   },
   "outputs": [],
   "source": [
    "train_encoding['1000344755']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:46:08.023730Z",
     "iopub.status.busy": "2022-04-12T15:46:08.023095Z",
     "iopub.status.idle": "2022-04-12T15:46:08.182714Z",
     "shell.execute_reply": "2022-04-12T15:46:08.181913Z",
     "shell.execute_reply.started": "2022-04-12T15:46:08.023689Z"
    }
   },
   "outputs": [],
   "source": [
    "from pickle import dump, load\n",
    "with open(\"../input/testenc/encoded_test_features.pkl\", \"rb\") as encoded_pickle:\n",
    "    encoding_test = load(encoded_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:46:13.914033Z",
     "iopub.status.busy": "2022-04-12T15:46:13.913242Z",
     "iopub.status.idle": "2022-04-12T15:46:13.921677Z",
     "shell.execute_reply": "2022-04-12T15:46:13.920887Z",
     "shell.execute_reply.started": "2022-04-12T15:46:13.913984Z"
    }
   },
   "outputs": [],
   "source": [
    "def greedySearch(photo):\n",
    "    in_text = 'startseq'\n",
    "    for i in range(max_len):\n",
    "        sequence = [word_to_index[w] for w in in_text.split() if w in word_to_index]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_len)\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = index_to_word[yhat]\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    final = in_text.split()\n",
    "    final = final[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:47:14.100730Z",
     "iopub.status.busy": "2022-04-12T15:47:14.099751Z",
     "iopub.status.idle": "2022-04-12T15:47:14.105535Z",
     "shell.execute_reply": "2022-04-12T15:47:14.104516Z",
     "shell.execute_reply.started": "2022-04-12T15:47:14.100690Z"
    }
   },
   "outputs": [],
   "source": [
    "z = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:47:15.517694Z",
     "iopub.status.busy": "2022-04-12T15:47:15.516924Z",
     "iopub.status.idle": "2022-04-12T15:47:16.384886Z",
     "shell.execute_reply": "2022-04-12T15:47:16.384115Z",
     "shell.execute_reply.started": "2022-04-12T15:47:15.517653Z"
    }
   },
   "outputs": [],
   "source": [
    "#z = 0\n",
    "z+=1\n",
    "pic = list(encoding_test.keys())[z]\n",
    "image = encoding_test[pic].reshape((1,4096))\n",
    "x=plt.imread(images+pic+'.jpg')\n",
    "plt.imshow(x)\n",
    "plt.show()\n",
    "print(\"Greedy:\",greedySearch(image))\n",
    "print(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:47:22.891269Z",
     "iopub.status.busy": "2022-04-12T15:47:22.890815Z",
     "iopub.status.idle": "2022-04-12T15:47:22.905221Z",
     "shell.execute_reply": "2022-04-12T15:47:22.904433Z",
     "shell.execute_reply.started": "2022-04-12T15:47:22.891232Z"
    }
   },
   "outputs": [],
   "source": [
    "test_content = {}\n",
    "\n",
    "for imageID in test_data:\n",
    "    test_content[imageID] = []\n",
    "    for caption in content[imageID]:\n",
    "        # Add a start sequence token in the beginning and an end sequence token at the end\n",
    "        cap_to_append = caption\n",
    "        test_content[imageID].append(cap_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:47:25.303859Z",
     "iopub.status.busy": "2022-04-12T15:47:25.303264Z",
     "iopub.status.idle": "2022-04-12T15:47:25.309830Z",
     "shell.execute_reply": "2022-04-12T15:47:25.308963Z",
     "shell.execute_reply.started": "2022-04-12T15:47:25.303818Z"
    }
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "pic = list(encoding_test.keys())[x]\n",
    "test_content[pic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:48:02.264370Z",
     "iopub.status.busy": "2022-04-12T15:48:02.263788Z",
     "iopub.status.idle": "2022-04-12T15:48:02.927282Z",
     "shell.execute_reply": "2022-04-12T15:48:02.926489Z",
     "shell.execute_reply.started": "2022-04-12T15:48:02.264331Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "x = 1\n",
    "pic = list(encoding_test.keys())[x]\n",
    "test_content[pic]\n",
    "\n",
    "\n",
    "reference = test_content[pic]\n",
    "#pic = list(encoding_test.keys())[1]\n",
    "print(pic)\n",
    "img = 'twodogs.jpg'\n",
    "e = encoding_test[pic].reshape(1,4096)\n",
    "#image = encoding_test[pic].reshape((1,2048))\n",
    "x=plt.imread(images+pic+'.jpg')\n",
    "#x=plt.imread(img)\n",
    "plt.imshow(x)\n",
    "# plt.show()\n",
    "caption = greedySearch(e)\n",
    "print(\"Greedy Search Caption:\",caption)\n",
    "print()\n",
    "print('Reference 1:',reference)\n",
    "\n",
    "print()\n",
    "print('BLEU-1:', round(sentence_bleu(reference, caption),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T10:40:03.670155Z",
     "iopub.status.busy": "2022-04-08T10:40:03.669637Z",
     "iopub.status.idle": "2022-04-08T10:40:03.67849Z",
     "shell.execute_reply": "2022-04-08T10:40:03.677713Z",
     "shell.execute_reply.started": "2022-04-08T10:40:03.670116Z"
    }
   },
   "outputs": [],
   "source": [
    "train_content[pic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T15:50:55.499997Z",
     "iopub.status.busy": "2022-04-12T15:50:55.499565Z",
     "iopub.status.idle": "2022-04-12T15:50:56.470502Z",
     "shell.execute_reply": "2022-04-12T15:50:56.469812Z",
     "shell.execute_reply.started": "2022-04-12T15:50:55.499915Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "x = 4328\n",
    "pic = list(train_encoding.keys())[x]\n",
    "train_content[pic]\n",
    "\n",
    "\n",
    "reference = train_content[pic]\n",
    "#pic = list(encoding_test.keys())[1]\n",
    "print(pic)\n",
    "img = 'twodogs.jpg'\n",
    "e = train_encoding[pic].reshape(1,4096)\n",
    "#image = encoding_test[pic].reshape((1,2048))\n",
    "x=plt.imread(images+pic+'.jpg')\n",
    "#x=plt.imread(img)\n",
    "plt.imshow(x)\n",
    "# plt.show()\n",
    "caption = greedySearch(e)\n",
    "print(\"Predicted Caption:\",caption)\n",
    "print()\n",
    "print('Reference 1:',reference)\n",
    "\n",
    "print()\n",
    "print('BLEU-1:', round(sentence_bleu(reference, caption),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T10:56:49.731529Z",
     "iopub.status.busy": "2022-03-28T10:56:49.730842Z",
     "iopub.status.idle": "2022-03-28T10:56:50.534852Z",
     "shell.execute_reply": "2022-03-28T10:56:50.533789Z",
     "shell.execute_reply.started": "2022-03-28T10:56:49.731486Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T10:57:56.018455Z",
     "iopub.status.busy": "2022-03-28T10:57:56.018175Z",
     "iopub.status.idle": "2022-03-28T10:57:56.023263Z",
     "shell.execute_reply": "2022-03-28T10:57:56.022597Z",
     "shell.execute_reply.started": "2022-03-28T10:57:56.018424Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T10:57:41.405547Z",
     "iopub.status.busy": "2022-03-28T10:57:41.405259Z",
     "iopub.status.idle": "2022-03-28T10:57:49.06497Z",
     "shell.execute_reply": "2022-03-28T10:57:49.064117Z",
     "shell.execute_reply.started": "2022-03-28T10:57:41.405504Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:11:06.663247Z",
     "iopub.status.busy": "2022-03-28T12:11:06.662986Z",
     "iopub.status.idle": "2022-03-28T12:11:14.064036Z",
     "shell.execute_reply": "2022-03-28T12:11:14.063098Z",
     "shell.execute_reply.started": "2022-03-28T12:11:06.663217Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:06:03.267135Z",
     "iopub.status.busy": "2022-03-28T12:06:03.266395Z",
     "iopub.status.idle": "2022-03-28T12:06:05.718153Z",
     "shell.execute_reply": "2022-03-28T12:06:05.717293Z",
     "shell.execute_reply.started": "2022-03-28T12:06:03.267097Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
